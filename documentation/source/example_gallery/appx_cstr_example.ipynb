{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate MPC with CSTR\n",
    "\n",
    "In this Jupyter Notebook, we illustrate the example **Approximate MPC with CSTR**.\n",
    "\n",
    "This example is an extension of the CSTR example and consists of three modules: **template_model.py**, which describes the system model; **template_mpc.py**, which defines the settings for the controller we want to approximate; and **template_simulator.py**, which sets the parameters for the simulator. In the **main.py** file, we introduce the concept of approximate MPC by generating training data, training on that data, and finally performing a closed-loop evaluation.\n",
    "\n",
    "In the following sections, each part is presented. We begin by importing basic modules and **do-mpc**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "from casadi.tools import *\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add do_mpc to path. This is not necessary if it was installed via pip\n",
    "rel_do_mpc_path = os.path.join('..', '..','..')\n",
    "sys.path.append(rel_do_mpc_path)\n",
    "\n",
    "# Import do_mpc package:\n",
    "import do_mpc\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will present the configuration, setup and connection between these blocks, starting with the `model`.\n",
    "The considered model of the CSTR is continuous and has 4 states and 2 control inputs.\n",
    "The model is initiated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'continuous' # either 'discrete' or 'continuous'\n",
    "model = do_mpc.model.Model(model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States and control inputs\n",
    "\n",
    "The four states are concentration of reactant A ($C_{\\text{A}}$), the concentration of reactant B ($C_{\\text{B}}$), the temperature inside the reactor ($T_{\\text{R}}$) and the temperature of the cooling jacket ($T_{\\text{K}}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# States struct (optimization variables):\n",
    "C_a = model.set_variable(var_type='_x', var_name='C_a', shape=(1,1))\n",
    "C_b = model.set_variable(var_type='_x', var_name='C_b', shape=(1,1))\n",
    "T_R = model.set_variable(var_type='_x', var_name='T_R', shape=(1,1))\n",
    "T_K = model.set_variable(var_type='_x', var_name='T_K', shape=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The control inputs are the feed $F$ and the heat flow $\\dot{Q}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input struct (optimization variables):\n",
    "F = model.set_variable(var_type='_u', var_name='F')\n",
    "Q_dot = model.set_variable(var_type='_u', var_name='Q_dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODE and parameters\n",
    "\n",
    "The system model is described by the ordinary differential equation:\n",
    "\n",
    "\\begin{align}\n",
    "\\dot{C}_{\\text{A}} &= F \\cdot (C_{\\text{A},0} - C_{\\text{A}}) - k_1 \\cdot C_{\\text{A}} - k_3 \\cdot C_{\\text{A}}^2, \\\\\n",
    "\\dot{C}_{\\text{B}} &= -F \\cdot C_{\\text{B}} + k_1 \\cdot C_{\\text{A}} - k_2 \\cdot C_{\\text{B}}, \\\\\n",
    "\\dot{T}_{\\text{R}} &= \\frac{k_1 \\cdot C_{\\text{A}} \\cdot H_{\\text{R},ab} + k_2 \\cdot C_{\\text{B}} \\cdot  H_{\\text{R},bc} + k_3 \\cdot C_{\\text{A}}^2 \\cdot H_{\\text{R},ad}} {-\\rho \\cdot c_p}\\\\\n",
    "&+ F \\cdot (T_{\\text{in}} - T_{\\text{R}}) + \\frac{K_w \\cdot A_{\\text{R}} \\cdot(T_{\\text{K}}-T_{\\text{R}})}{\\rho \\cdot c_p \\cdot V_{\\text{R}}}, \\\\\n",
    "\\dot{T}_{\\text{K}} &= \\frac{\\dot{Q} + K_w \\cdot A_{\\text{R}} \\cdot T_{\\text{dif}}}{m_k \\cdot C_{p,k}},\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align}\n",
    "k_1 &= \\beta \\cdot k_{0,\\text{ab}} \\cdot \\exp\\left(\\frac{-E_{\\text{A},\\text{ab}}}{T_{\\text{R}}+273.15}\\right), \\\\\n",
    "k_2 &= k_{0,\\text{bc}} \\cdot \\exp \\left( \\frac{-E_{\\text{A},\\text{bc}}}{T_{\\text{R}}+273.15} \\right), \\\\\n",
    "k_3 &= k_{0,\\text{ad}} \\cdot \\exp \\left( \\frac{-\\alpha \\cdot E_{\\text{A},\\text{ad}}}{T_{\\text{R}}+273.15} \\right).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain parameters\n",
    "K0_ab = 1.287e12 # K0 [h^-1]\n",
    "K0_bc = 1.287e12 # K0 [h^-1]\n",
    "K0_ad = 9.043e9 # K0 [l/mol.h]\n",
    "R_gas = 8.3144621e-3 # Universal gas constant\n",
    "E_A_ab = 9758.3*1.00 #* R_gas# [kj/mol]\n",
    "E_A_bc = 9758.3*1.00 #* R_gas# [kj/mol]\n",
    "E_A_ad = 8560.0*1.0 #* R_gas# [kj/mol]\n",
    "H_R_ab = 4.2 # [kj/mol A]\n",
    "H_R_bc = -11.0 # [kj/mol B] Exothermic\n",
    "H_R_ad = -41.85 # [kj/mol A] Exothermic\n",
    "Rou = 0.9342 # Density [kg/l]\n",
    "Cp = 3.01 # Specific Heat capacity [kj/Kg.K]\n",
    "Cp_k = 2.0 # Coolant heat capacity [kj/kg.k]\n",
    "A_R = 0.215 # Area of reactor wall [m^2]\n",
    "V_R = 10.01 #0.01 # Volume of reactor [l]\n",
    "m_k = 5.0 # Coolant mass[kg]\n",
    "T_in = 130.0 # Temp of inflow [Celsius]\n",
    "K_w = 4032.0 # [kj/h.m^2.K]\n",
    "C_A0 = (5.7+4.5)/2.0*1.0 # Concentration of A in input Upper bound 5.7 lower bound 4.5 [mol/l]\n",
    "alpha=1\n",
    "beta=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we formulate the $k_i$-s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary terms\n",
    "K_1 = beta * K0_ab * exp((-E_A_ab)/((T_R+273.15)))\n",
    "K_2 =  K0_bc * exp((-E_A_bc)/((T_R+273.15)))\n",
    "K_3 = K0_ad * exp((-alpha*E_A_ad)/((T_R+273.15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we define an artificial variable of interest, that is not a state of the system, but will be later used for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_dif = model.set_expression(expr_name='T_dif', expr=T_R-T_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of the $k_i$-s and $T_{\\text{dif}}$ we can define the ODEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_rhs('C_a', F*(C_A0 - C_a) -K_1*C_a - K_3*(C_a**2))\n",
    "model.set_rhs('C_b', -F*C_b + K_1*C_a - K_2*C_b)\n",
    "model.set_rhs('T_R', ((K_1*C_a*H_R_ab + K_2*C_b*H_R_bc + K_3*(C_a**2)*H_R_ad)/(-Rou*Cp)) + F*(T_in-T_R) +(((K_w*A_R)*(-T_dif))/(Rou*Cp*V_R)))\n",
    "model.set_rhs('T_K', (Q_dot + K_w*A_R*(T_dif))/(m_k*Cp_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model setup is complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the model predictive controller is configured. This is needed as the approximate MPC is a supervised training approach, where the training data is generated by the MPC. Therefore, the MPC and the model specifies the behavior of the approximate MPC.\n",
    "First, one member of the mpc class is generated with the prediction model defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc = do_mpc.controller.MPC(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the prediction horizon `n_horizon`, set the robust horizon `n_robust` to 0.\n",
    "It is possible to use the approximate MPC for robust MPC, but in its current only open-loop sampling can be used as a sampling strategy for the robust MPC.\n",
    "The time step `t_step` is set to 0.005h and parameters of the applied discretization scheme orthogonal collocation are as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set settings of MPC:\n",
    "mpc.settings.n_horizon = 20\n",
    "mpc.settings.n_robust = 0\n",
    "mpc.settings.open_loop = 0\n",
    "mpc.settings.t_step = 0.005\n",
    "mpc.settings.state_discretization = 'collocation'\n",
    "mpc.settings.collocation_type = 'radau'\n",
    "mpc.settings.collocation_deg = 2\n",
    "mpc.settings.collocation_ni = 1\n",
    "mpc.settings.store_full_solution = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the magnitude of the states and inputs is very different, we introduce scaling factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc.scaling['_x', 'T_R'] = 100\n",
    "mpc.scaling['_x', 'T_K'] = 100\n",
    "mpc.scaling['_u', 'Q_dot'] = 2000\n",
    "mpc.scaling['_u', 'F'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The goal of the CSTR is to obtain a mixture with a concentration of $C_{\\text{B,ref}} = 0.6$ mol/l.\n",
    "Additionally, we add a penalty on input changes for both control inputs, to obtain a smooth control performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mterm = (model.x['C_b'] - 0.6)**2+(model.x['C_a'] - 0.7)**2\n",
    "lterm = (model.x['C_b'] - 0.6)**2+(model.x['C_a'] - 0.7)**2\n",
    "\n",
    "mpc.set_objective(mterm=mterm, lterm=lterm)\n",
    "\n",
    "mpc.set_rterm(F=0.1, Q_dot = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints\n",
    "\n",
    "In the next step, the constraints of the control problem are set.\n",
    "In this case, there are only upper and lower bounds for each state and the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower bounds of the states\n",
    "mpc.bounds['lower', '_x', 'C_a'] = 0.1\n",
    "mpc.bounds['lower', '_x', 'C_b'] = 0.1\n",
    "mpc.bounds['lower', '_x', 'T_R'] = 50\n",
    "mpc.bounds['lower', '_x', 'T_K'] = 50\n",
    "\n",
    "# upper bounds of the states\n",
    "mpc.bounds['upper', '_x', 'C_a'] = 2\n",
    "mpc.bounds['upper', '_x', 'C_b'] = 2\n",
    "mpc.bounds['upper', '_x', 'T_R'] = 140\n",
    "mpc.bounds['upper', '_x', 'T_K'] = 140\n",
    "\n",
    "# lower bounds of the inputs\n",
    "mpc.bounds['lower', '_u', 'F'] = 5\n",
    "mpc.bounds['lower', '_u', 'Q_dot'] = -8500\n",
    "\n",
    "# upper bounds of the inputs\n",
    "mpc.bounds['upper', '_u', 'F'] = 100\n",
    "mpc.bounds['upper', '_u', 'Q_dot'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup of the MPC controller is concluded by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator\n",
    "\n",
    "We assume, that all states can be directly measured (state-feedback):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = do_mpc.estimator.StateFeedback(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator\n",
    "\n",
    "To create a simulator to run the approximate MPC in a closed-loop, we create an instance of the **do-mpc** simulator which is based on the same model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = do_mpc.simulator.Simulator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simulation, we use the same time step `t_step` as for the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_simulator = {\n",
    "        'integration_tool': 'cvodes',\n",
    "        'abstol': 1e-10,\n",
    "        'reltol': 1e-10,\n",
    "        't_step': 0.005\n",
    "    }\n",
    "\n",
    "simulator.set_param(**params_simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish the configuration of the simulator, call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the MPC and Simulator\n",
    "\n",
    "For the initialization of the MPC configured for the CSTR, we inspect the file **main.py**.\n",
    "We define the initial state of the system and set it for all parts of the closed-loop configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial state of mpc and simulator:\n",
    "C_a_0 = 0.8 # This is the initial concentration inside the tank [mol/l]\n",
    "C_b_0 = 0.5 # This is the controlled variable [mol/l]\n",
    "T_R_0 = 134.14 #[C]\n",
    "T_K_0 = 130.0 #[C]\n",
    "x0 = np.array([C_a_0, C_b_0, T_R_0, T_K_0]).reshape(-1,1)\n",
    "u0=np.array([[5],[0]])\n",
    "\n",
    "# pushing to class\n",
    "mpc.u0=u0\n",
    "mpc.x0 = x0\n",
    "simulator.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "simulator.set_initial_guess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate MPC\n",
    "\n",
    "So far, we have only initialized our model, the MPC and the Simulator, which is like the usage of a MPC for controlling the system. In the next steps we must configure our approximate MPC, the Sampler for generating training data and the Trainer for training the Approximate MPC.\n",
    "These three classes are the main components of the Approximate MPC. As it is standard in do-mpc, each of these classes can be configured using the settings of the respective class. After calling **setup()** the instance of the class is ready to be used.\n",
    "First, the Approximate MPC is configured. One member of the ApproximateMPC class is generated which is initialized with the MPC class defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_mpc = do_mpc.approximateMPC.ApproxMPC(mpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appropriate sizes for number of hidden layers `n_hidden_layers` and number of neurons per layer `n_neurons` are chosen in this example using the settings class. Note that default parameters of each settings parameter are provided.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_mpc.settings.n_hidden_layers = 1\n",
    "approx_mpc.settings.n_neurons = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other setting parameters for the approximate MPC include the activation function and the device on which the approximate MPC should run. The setup of the Approximate MPC controller is concluded by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler\n",
    "\n",
    "Next, a Sampler is configured. This class is used to generate training data for Approximate MPC.\n",
    "It uses the already established sampling planner of do-mpc, son in case you want to take a deep dive into generating data with do-mpc, you can revisit the respective example. This class also needs to be initialized with the MPC class as it uses the MPC to generate the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = do_mpc.approximateMPC.AMPCSampler(mpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the Sampler settings are configured. Currently, we support two sampling approaches, the open-loop standard sampling, where **n_samples** random data is sampled within the bounds of the MPC. The `closed_loop_flag` can be used to use a closed-loop sampling approach where closed loop trajectories of the length **trajectory_length**. Note that now **n_samples*trajectory_length** sampling data points are generated. In fact, in this example we do open loop sampling by setting `trajectory_length=1` but are showing how to use the closed loop sampling method in general. Again, these parameters are set through the settings class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.settings.closed_loop_flag = True\n",
    "sampler.settings.trajectory_length = 1\n",
    "sampler.settings.n_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of samples is a mandatory setting. The other one is the name of the dataset. You can also set the directory in which this dataset is stored which is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= './sampling_notebook'\n",
    "sampler.settings.data = data_dir\n",
    "dataset_name = \"my_dataset\"\n",
    "sampler.settings.dataset_name = dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup of the Sampler class is concluded by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sampler is now used to generate the sample data on which the ApproximateMPC will be trained further. for this a default sampling plan is used. This iteratively calculates the training data, so depending on `n_samples` and the complexity of the MPC controller, it might take a while. (The output of the MPC is suppressed with the magic command `%%capture`) For this example we have already generated the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#sampler.default_sampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "Next, a Trainer is configured. The Trainer is used to train the approximate MPC on the generated training data. Therefore, the Trainer is initialized with the ApproximateMPC class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = do_mpc.approximateMPC.Trainer(approx_mpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the trainer setting parameters are configured. Make sure to set the right direction for the training data, which is done by setting the `data_dir` and the right name of the dataset.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.settings.data_dir = data_dir\n",
    "trainer.settings.dataset_name = dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the hyper-parameters for the training of the approximate MPC such as `n_epochs`. The Trainer also can use the learning rate scheduler of Pytorch for which the parameters can be set with the `scheduler_settings`. This can improve the training performance when hitting a plateau, by reducing the learning rate, so that the loss does not oscillate around the optimal point. It is set to `False` as we do not need it for this simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.settings.n_epochs = 3000\n",
    "trainer.settings.scheduler_flag = False\n",
    "trainer.scheduler_settings.cooldown = 0\n",
    "trainer.scheduler_settings.patience = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display and save the performance of the training, the following flags may be set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.settings.show_fig =True\n",
    "trainer.settings.save_fig = True\n",
    "trainer.settings.save_history = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location where the samples data is stored is provided with `results_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.settings.results_dir = './training_notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the trainer is setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is initiated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "torch.manual_seed(42)\n",
    "trainer.default_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closed loop simulation\n",
    "\n",
    "Now all we are ready for simulating the system with the newly trained approximate MPC controller, for 50 steps. As for the MPC the `make_step` function of the approximate MPC is used where instead of solving an optimization problem the pre-trained neural network is evaluated. It is possible to clip the control inputs to the bounds of the MPC controller with the flag `clip_to_bounds=True`.\n",
    "\n",
    "When `clip_to_bounds=True`, the inputs are forced to be within the set upper boundary and the set lower boundary, ensuring that no matter what, the inputs are within permissible bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_time = 100\n",
    "approx_mpc.u0=u0\n",
    "for k in range(sim_time):\n",
    "    u0 = approx_mpc.make_step(x0, clip_to_bounds=True)\n",
    "    y_next = simulator.make_step(u0)\n",
    "    x0 = estimator.make_step(y_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "To animate the results, we first configure the **do-mpc** graphics object, which is initiated with the respective data object:\n",
    "\n",
    "Here we use `simulator.data`, since the simulator consists of the class which stores the data which can be extracted. As a contrast, the data from the mpc class cannot be used, since in the main simulation loop, mpc class is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_graphics = do_mpc.graphics.Graphics(simulator.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a figure, configure which lines to plot on which axis and add labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(5, sharex=True, figsize=(16,12))\n",
    "# Configure plot:\n",
    "sim_graphics.add_line(var_type='_x', var_name='C_a', axis=ax[0])\n",
    "sim_graphics.add_line(var_type='_x', var_name='C_b', axis=ax[0])\n",
    "sim_graphics.add_line(var_type='_x', var_name='T_R', axis=ax[1])\n",
    "sim_graphics.add_line(var_type='_x', var_name='T_K', axis=ax[1])\n",
    "sim_graphics.add_line(var_type='_aux', var_name='T_dif', axis=ax[2])\n",
    "sim_graphics.add_line(var_type='_u', var_name='Q_dot', axis=ax[3])\n",
    "sim_graphics.add_line(var_type='_u', var_name='F', axis=ax[4])\n",
    "ax[0].set_ylabel('c [mol/l]')\n",
    "ax[1].set_ylabel('T [K]')\n",
    "ax[2].set_ylabel('$\\Delta$ T [K]')\n",
    "ax[3].set_ylabel('Q [kW]')\n",
    "ax[4].set_ylabel('Flow [l/h]')\n",
    "ax[4].set_xlabel('time [h]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cstranim](anim_CSTR_approx_nb.gif \"cstr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appx_mpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
